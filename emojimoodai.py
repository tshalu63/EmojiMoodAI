# -*- coding: utf-8 -*-
"""EmojiMoodAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jxnzu9o52nkAB5uLoj_pkXigrWx4XsDH
"""

!pip install -q sentence-transformers gradio

from sentence_transformers import SentenceTransformer
import torch
import gradio as gr
import numpy as np

# Sample sentences
texts = [
    "I am very happy today", "Feeling great and excited", "This is amazing",
    "I am sad", "Feeling down", "I am lonely",
    "I am angry", "This annoys me", "Frustrated about work",
    "Feeling relaxed", "Chilling at home", "Peaceful day",
    "I am in love", "So tired and exhausted", "I am scared"
]

# Corresponding emojis (can map multiple moods)
emojis_list = [
    ["ğŸ˜„"], ["ğŸ˜„"], ["ğŸ˜„"],
    ["ğŸ˜¢"], ["ğŸ˜¢"], ["ğŸ˜¢"],
    ["ğŸ˜¡"], ["ğŸ˜¡"], ["ğŸ˜¡"],
    ["ğŸ˜Œ"], ["ğŸ˜Œ"], ["ğŸ˜Œ"],
    ["ğŸ˜"], ["ğŸ˜´"], ["ğŸ˜±"]
]

# Load pretrained model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Compute embeddings for dataset sentences
embeddings = model.encode(texts, convert_to_tensor=True)

def predict_emojis(user_input, top_k=2):
    """
    Predict the top_k emojis for a given input sentence.
    """
    user_emb = model.encode([user_input], convert_to_tensor=True)
    cos_sim = torch.nn.functional.cosine_similarity(user_emb, embeddings)

    # Get indices of top_k most similar sentences
    top_indices = torch.topk(cos_sim, k=top_k).indices.tolist()

    # Collect emojis (remove duplicates)
    predicted_emojis = []
    for idx in top_indices:
        for e in emojis_list[idx]:
            if e not in predicted_emojis:
                predicted_emojis.append(e)

    return " ".join(predicted_emojis)

iface = gr.Interface(
    fn=predict_emojis,
    inputs=[gr.Textbox(label="Enter a sentence"), gr.Slider(1, 5, step=1, label="Number of top emojis")],
    outputs="text",
    title="Emoji Mood Predictor",
    description="Type a sentence and see the top emojis representing its mood!"
)

iface.launch(share=True)